{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8e2a8c7-e42d-42b5-a18f-e8944628caea",
   "metadata": {
    "tags": []
   },
   "source": [
    "# (10주차) 5월9일\n",
    "\n",
    "- toc:true\n",
    "- branch: master\n",
    "- badges: true\n",
    "- comments: true\n",
    "- author: 최규빈"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfd4e68-d467-4efc-ba3b-81b54cde449e",
   "metadata": {},
   "source": [
    "## 강의영상 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7adcbed-1805-4f27-992a-6d59a6159d18",
   "metadata": {},
   "source": [
    "> youtube: https://youtube.com/playlist?list=PLQqh36zP38-yOW-cMOTA1JYUZ2PJKBAgA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db05e967-efd3-4e9d-acc5-c7d0c065889d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 평가지표"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ead556-41a8-451c-91ef-fab24cdaf382",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 다양한 평가지표들 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a49be17-0183-4a71-8fb7-9dc096fcd301",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`-` 의문: 왜 다양한 평가지표가 필요한가? (accuray면 끝나는거 아닌가? 더 이상 뭐가 필요해?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11fe9b2-636b-47c4-9dad-8624050b146c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`-` 여러가지 평가지표들: https://en.wikipedia.org/wiki/Positive_and_negative_predictive_values\n",
    "- 이걸 다 암기하는건 불가능함. \n",
    "- 몇 개만 뽑아서 암기하고 왜 쓰는지만 생각해보고 넘어가자!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03880c3-2377-45df-8fc8-f00276d5e661",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### confusion matrix의 이해 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9986f7-6b2f-42b5-ae4d-3b31d2d83e45",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "`-` 표1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81a4f39-532d-4a0a-8a4d-878076ccc762",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "| |퇴사(예측)|안나감(예측)|\n",
    "|:-:|:-:|:-:|\n",
    "|퇴사(실제)|TP|FN|\n",
    "|안나감(실제)| FP| TN|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2878f8-d5f3-4a7c-8b1e-8546c8bcd868",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "`-` 표2 (책에없음) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591a646c-5d97-4796-b40f-a18c3bbea043",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "| |퇴사(예측)|안나감(예측)|\n",
    "|:-:|:-:|:-:|\n",
    "|퇴사(실제)|$(y,\\hat{y})= $ (O,O)|$(y,\\hat{y})= $(O,X)|\n",
    "|안나감(실제)| $(y,\\hat{y})= $(X,O)| $(y,\\hat{y})= $(X,X)|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a716310-ba96-443d-86cc-5883a8cc67c9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "`-` 표3 (책에없음) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a4b55b-1da2-49af-be44-77d572962b7a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "| |퇴사(예측)|안나감(예측)|\n",
    "|:-:|:-:|:-:|\n",
    "|퇴사(실제)|TP, $\\# O/O$ |FN, $\\#O/X$|\n",
    "|안나감(실제)| FP, $\\#X/O$| TN, $\\#X/X$|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0521068-4498-44c8-ac66-7f194acb5abb",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- 암기법, (1) 두번째 글자를 그대로 쓴다 (2) 첫글자가 T이면 분류를 제대로한것, 첫글자가 F이면 분류를 잘못한것"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd347f38-9705-4ea5-bcca-cee5adbd309a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "`-` 표4 (위키등에 있음) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d770cb-286f-4555-ac04-9c90c1559377",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "| |퇴사(예측)|안나감(예측)| |\n",
    "|:-:|:-:|:-:|:-:|\n",
    "|퇴사(실제)| TP, $\\# O/O$ |FN, $\\# O/X$| Sensitivity(민감도)=Recall(재현율)=$\\frac{TP}{TP+FN}$=$\\frac{\\#O/O}{\\# O/O+ \\#O/X}$|\n",
    "|안나감(실제)| FP, $\\# X/O$| TN, $\\# X/X$| |\n",
    "| |Precision(프리시즌)=$\\frac{TP}{TP+FP}$=$\\frac{\\# O/O}{\\# O/O+\\# X/O}$| |Accuracy(애큐러시)=$\\frac{TP+TN}{total}$=$\\frac{\\#O/O+\\# X/X}{total}$|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da99fe51-9535-4c93-b98d-d5b773f790c8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 상황극 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c7b65e-179e-4731-aec3-5f77c6323e6f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`-` 최규빈은 입사하여 \"퇴사자 예측시스템\"의 개발에 들어갔다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be309291-aade-4fca-9769-c20a905ae53a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`-` 자료의 특성상 대부분의 사람이 퇴사하지 않고 회사에 잘 다닌다. 즉 1000명이 있으면 10명정도 퇴사한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ac1c42-7869-4ee6-8fb6-aa48f60e34d2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bed955-f34f-4a9d-b693-f7e1c790e160",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`-` 정의: Accuracy(애큐러시)=$\\frac{TP+TN}{total}$=$\\frac{\\#O/O+ \\#X/X}{total}$\n",
    "- 한국말로는 정확도, 정분류율이라고 한다. \n",
    "- 한국말이 헷갈리므로 그냥 영어를 외우는게 좋다. (어차피 Keras에서 옵션도 영어로 넣음) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3085a6e1-2255-4390-9772-ded2f4a09353",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "`-` (상확극 시점1) 왜 애큐러시는 불충분한가?\n",
    "- 회사: 퇴사자예측프로그램 개발해\n",
    "- 최규빈: 귀찮은데 다 안나간다고 하자! -> 99퍼의 accuracy \n",
    "\n",
    "> 모델에 사용한 파라메터 = 0. 그런데 애큐러시 = 99! 이거 엄청 좋은 모형이다? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324a3581-8293-4062-9430-235442d3b889",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sensitivity(민감도), Recall(재현율), True Positive Rate(TPR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50277f41-2ccb-4262-b48f-78fc5f77d12d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`-` 정의: Sensitivity(민감도)=Recall(재현율)=$\\frac{TP}{TP+FN}$=$\\frac{\\# O/O}{\\# O/O+\\# O/X}$\n",
    "- 분모: 실제 O인 관측치 수 \n",
    "- 분자: 실제 O를 O라고 예측한 관측치 수 \n",
    "- 뜻: 실제 O를 O라고 예측한 비율"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf04b205-c102-4277-83f3-15c88b040f93",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "`-` (상황극 시점2) recall을 봐야하는 이유\n",
    "- 인사팀: 실제 퇴사자를 퇴사자로 예측해야 의미가 있음! 우리는 퇴사할것 같은 10명을 찍어달란 의미였어요! (그래야 면담을 하든 할거아냐!) \n",
    "- 최규빈: 가볍고(=파라메터 적고) 잘 맞추는 모형 만들어 달라면서요?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcf704e-b5dc-419f-9944-6b605310e893",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- 인사팀: (고민중..) 사실 생각해보니까 이 경우는 애큐러시는 의미가 없네. 실제 나간 사람 중 최규빈이 나간다고 한 사람이 몇인지 카운트 하는게 더 의미가 있겠다. 우리는 앞으로 리컬(혹은 민감도)를 보겠다! \n",
    "\n",
    "> 예시1: 실제로 퇴사한 10명중 최규빈이 나간다고 찍은 사람이 5명이면 리컬이 50% \n",
    "\n",
    "> 예시2: 최규빈이 아무도 나가지 않는다고 예측해버린다? 실제 10명중에서 최규빈이 나간다고 적중시킨사람은 0명이므로 이 경우 리컬은 0%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88fa3f0-a0b8-47d3-885e-7bfbb8f1a4cf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- 결론: 우리가 필요한건 recall이니까 앞으로 recall을 가져와! accuracy는 큰 의미없어. (그래도 명색이 모델인데 accuracy가 90은 되면 좋겠다)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbd4bbf-6dd3-4bce-b1f7-da285385b020",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7c0969-1cdf-42b4-9627-f3d2a0cd3db9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`-` 정의: Precision(프리시즌)=$\\frac{TP}{TP+FP}$=$\\frac{\\# O/O}{\\# O/O+\\# X/O}$\n",
    "- 분모: O라고 예측한 관측치\n",
    "- 분자: O라고 예측한 관측치중 진짜 O인 관측치 \n",
    "- 뜻: O라고 예측한 관측치중 진짜 O인 비율"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4607fb7-d616-4a05-9928-14c6ff65c53e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "`-` (상황극 시점3) recall 만으로 불충분한 이유\n",
    "\n",
    "- 최규빈: 에휴.. 귀찮은데 그냥 좀만 수틀리면 다 나갈것 같다고 해야겠다. -> 한 100명 나간다고 했음 -> 실제로 최규빈이 찍은 100명중에 10명이 다 나감!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6e234f-a240-45d6-bc4c-aad94f2ab5c2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> 이 경우 애큐러시는 91%, 리컬은 100% (퇴사자 10명을 일단은 다 맞췄으므로). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7121d79c-51e8-4a72-bcf9-c795ac270ea9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- 인사팀: (화가 많이 남) 멀쩡한 사람까지 다 퇴사할 것 같다고 하면 어떡해요? 최규빈 연구원이 나간다고 한 100명중에 실제로 10명만 나갔어요. \n",
    "\n",
    "- 인사팀: 마치 총으로 과녁중앙에 맞춰 달라고 했더니 기관총을 가져와서 한번 긁은것이랑 뭐가 달라요? 맞추는게 문제가 아니고 precision이 너무 낮아요. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f06c18-004f-42dd-a9f7-63310b8015c0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- 최규빈: accuracy 90% 이상, recall은 높을수록 좋다는게 주문 아니었나요? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b63ce63-7807-4f63-ac95-af2cd67dca8f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- 인사팀: (고민중..) 앞으로는 recall과 함께 precision도 같이 제출하세요. precision은 당신이 나간다고 한 사람중에 실제 나간사람의 비율을 의미해요. 이 경우는 $\\frac{10}{100}$이니까 precision이 10%입니다. (속마음: recall 올리겠다고 무작정 너무 많이 예측하지 말란 말이야!) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1835da-5d3e-4c1f-a54e-64b098c8ddfd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### F1 score "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68ba992-3650-4942-8894-991b0a5b032d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "`-` 정의: recall과 precision의 조화평균 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f69935-0a4b-4ac0-94da-b5dfd129b82e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "`-` (상황극 시점4) recall, precision을 모두 고려 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec04a7c-eb2b-437e-b2d1-ab241f623358",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- 최규빈: recall/precision을 같이 내는건 좋은데요, 둘은 trade off의 관계에 있습니다. 물론 둘다 올리는 모형이 있다면 좋지만 그게 쉽지는 않아요. 보통은 precision을 올리려면 recall이 희생되는 면이 있고요, recall을 올리려고 하면 precision이 다소 떨어집니다. \n",
    "\n",
    "- 최규빈: 평가기준이 애매하다는 의미입니다. 모형1,2가 있는데 모형1은 모형2보다 precision이 약간 좋고 대신 recall이 떨어진다면 모형1이 좋은것입니까? 아니면 모형2가 좋은것입니까? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4789eb49-9f47-4d79-ab0f-c858a33e2ed4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- 인사팀: 그렇다면 둘을 평균내서 F1score를 계산해서 제출해주세요. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b81eea-d83d-4e8e-87ad-b2e8bfa56ca3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Specificity(특이도), False Positive Rate(FPR) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b20d86-10c5-420a-af92-0dedce4314a3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`-` 정의: \n",
    "\n",
    "(1) Specificity(특이도)=$\\frac{TN}{FP+TN}$=$\\frac{\\# X/X}{\\# X/O+\\# X/X}$\n",
    "\n",
    "(2) False Positive Rate (FPR) = 1-Specificity(특이도) = $\\frac{FP}{FP+TN}$=$\\frac{\\# X/O}{\\# X/O+\\# X/X}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46266a16-c55e-4580-ae13-2a14801f61bf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "`-` 의미: **FPR = 오해해서 미안해, recall(=TPR)을 올리려고 보니 어쩔 수 없었어 ㅠㅠ**\n",
    "- specificity는 안나간 사람을 안나갔다고 찾아낸 비율인데 별로 안중요하다. \n",
    "- FPR은 recall을 올리기 위해서 \"실제로는 회사 잘 다니고 있는 사람 중 최규빈이 나갈것 같다고 찍은 사람들\" 의 비율이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeaca4cc-c0e0-420e-b7d6-9380375711f1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> 즉 생사람잡은 비율.. 오해해서 미안한 사람의 비율.. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca16c560-e973-481a-9933-11fdf2b9b31b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ROC curve "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7ec421-3444-4dab-b108-48074e660479",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`-` 정의: $x$축=FPR, $y$축=TPR 을 그린 커브 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974f8263-b0d8-4c5b-87e5-73c9ecc8e4f5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`-` 의미: \n",
    "- 결국 \"오해해서 미안해 vs recall\"을 그린 곡선이 ROC커브이다. \n",
    "- 생각해보면 오해하는 사람이 많을수록 당연히 recall은 올라간다. 따라서 우상향하는 곡선이다. \n",
    "- 오해한 사람이 매우 적은데 recall이 우수하면 매우 좋은 모형이다. 그래서 초반부터 ROC값이 급격하게 올라가면 좋은 모형이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c8246a-f0e4-4a88-a73a-ffd61ef9572e",
   "metadata": {},
   "source": [
    "## fashion_mnist (revisit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48277a01-48ca-47dc-8ae3-0651d6a4396b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import tensorflow.experimental.numpy as tnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3055fa0a-738a-4876-9be7-9a8e60f915f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tnp.experimental_enable_numpy_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59a4c33c-9afa-4810-ae1c-e0ba3d24d087",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58db7361-2c43-45cf-88ed-6ae352c47f2a",
   "metadata": {},
   "source": [
    "`-` fashion mnist data 다시 불러오자 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f89bda8-1e45-4a27-b23e-d229655eaab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b95c80f-9e9b-46f1-b375-591a5c20763d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09541cbf-1c52-4a42-8772-a9ff2e07927a",
   "metadata": {},
   "source": [
    "- 이미지는 원래 가로픽셀 * 세로픽셀 * 3 이어야 한다. (색을 표현하는 basis는 빨,녹,파)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d3a644-6252-4ff8-8b39-c8b28b80557a",
   "metadata": {},
   "source": [
    "`-` 따라서 이미지의 차원이 단지 (28,28)이라는 것은 흑백이미지라는 뜻이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6de09f5c-1a82-45d8-bd88-63e68aef369b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fdf95b91240>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc6ecd9-164d-4d32-973f-8111854bd7f1",
   "metadata": {},
   "source": [
    "- 아닌데요?! 칼라인데요?! -> 흑백이다. 그냥 밝을수록 노란색, 어두울수록 남색으로 표현한것 뿐임 (colormap이 viridis일 뿐임)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd46838-3f6b-4304-9cf5-ff279d66d273",
   "metadata": {},
   "source": [
    "`-` 일반적으로 분석할 이미지는 칼라를 의미하는 채널도 포함할테니 아래와 같이 자료형을 정리하는게 일반적으로 이미지 자료를 분석하는 정석적인 처리방법이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b99b48d4-ab29-4af6-9601-bdbd8755aa72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-11 11:04:15.023063: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "X = tf.constant(x_train.reshape(-1,28,28,1),dtype=tf.float64)\n",
    "y = tf.keras.utils.to_categorical(y_train)\n",
    "XX = tf.constant(x_test.reshape(-1,28,28,1),dtype=tf.float64)\n",
    "yy = tf.keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36dc7cec-4207-4c83-a9fb-1f85b759e1dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([60000, 28, 28, 1]), TensorShape([10000, 28, 28, 1]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, XX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4a0070-311e-4a6f-85fb-40d72b63efac",
   "metadata": {},
   "source": [
    "- keras에서 이미지자료는 (관측치수,픽셀,픽셀,채널)과 같은 형식을 가진다. \n",
    "- 예를들어 256*256 size인 칼라이미지(채널수=3)가 10개 있다면 X.shape은 (10,256,256,3)이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a65fecf-c39c-4ae0-bf9b-b6aba7355ec2",
   "metadata": {},
   "source": [
    "## X의 차원이 (관측치수,픽셀,픽셀,채널)일 경우 DNN 쓰기 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf148f4-1af9-43b4-b095-b8385f8f17aa",
   "metadata": {},
   "source": [
    "### (예제1) X -> Dense(30,relu) -> Dense(10,softmax):=> y "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ceaf88d-1223-45b1-8933-ac0ecd619eee",
   "metadata": {},
   "source": [
    "`-` 이러한 아키텍처를 돌리기 위해서는 X의 shape을 미리 바꿔야 했었다. 혹시 바꾸지 않는 방법도 있을까? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbfe2ae-5d72-43d3-a642-6fcc8a1bbf07",
   "metadata": {},
   "source": [
    "`-` tf.keras.layers.Flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb965b75-65e4-45ae-971a-a1b135cae366",
   "metadata": {},
   "outputs": [],
   "source": [
    "flttn = tf.keras.layers.Flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e6ab7e9-6103-4369-bd9e-c2b725850346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.flatten.Flatten at 0x7fdf95bd6410>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flttn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723f703e-1807-4737-9ab2-27428fe73fb8",
   "metadata": {},
   "source": [
    "- type: flatten <- 머 어쩌란거야.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d892f90-3d93-455a-843b-d424d95ff752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__call__'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dir(flttn)) & {'__call__'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52c960d-04da-4525-8a73-d391efc0c1cc",
   "metadata": {},
   "source": [
    "- call이 있음 -> 써보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f3254ee-7edb-411b-b752-d38b519ed106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([60000, 28, 28, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4979139-eabb-4d6b-bc44-319de248d31e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(60000, 784), dtype=float32, numpy=\n",
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flttn(X) # 오..? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded6a05c-328d-44ee-b32c-ef1019032320",
   "metadata": {},
   "source": [
    "펴진다? 즉 X.reshape(-1,784)와 같은 기능!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c95797d-732b-47d1-b5f1-247db7c8bbe1",
   "metadata": {},
   "source": [
    "`-` 근데 이거 레이어다? 즉 네트워크에 add 할 수 있다는 의미!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931319b2-1cc8-4447-8a92-141b170cb8dd",
   "metadata": {},
   "source": [
    "`-` 그렇다면 아래와 같이 예제를 풀어도 괜찮겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d717205-afb2-4dd0-9fca-f01dc3567623",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 2s 676us/step - loss: 2.5317 - accuracy: 0.4077\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 1s 658us/step - loss: 1.2412 - accuracy: 0.4935\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 1s 666us/step - loss: 1.1642 - accuracy: 0.5133\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 1s 665us/step - loss: 1.0876 - accuracy: 0.5432\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 1s 654us/step - loss: 1.0204 - accuracy: 0.5777\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdf20233cd0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(43052)\n",
    "net1 = tf.keras.Sequential()\n",
    "net1.add(tf.keras.layers.Flatten())\n",
    "net1.add(tf.keras.layers.Dense(30,activation='relu'))\n",
    "net1.add(tf.keras.layers.Dense(10,activation='softmax'))\n",
    "net1.compile(loss=tf.losses.categorical_crossentropy, optimizer='adam',metrics=['accuracy'])\n",
    "net1.fit(X,y,epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c504671-9cc5-4837-9995-9494dff60eba",
   "metadata": {},
   "source": [
    "`-` 관찰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ce8af5a-2e87-4e63-b111-150463b5f1f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.flatten.Flatten at 0x7fdf8a5ba860>,\n",
       " <keras.layers.core.dense.Dense at 0x7fe088c06a70>,\n",
       " <keras.layers.core.dense.Dense at 0x7fdf95b559c0>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net1.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c6c65c8-6c2e-4ea3-8579-ed7011895771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(60000, 784), dtype=float32, numpy=\n",
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net1.layers[0](X) # 레이어를 통과하는 순간 전처리!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50204301-cc61-4d74-b2d9-0ddcb5e7e4d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(60000, 30), dtype=float32, numpy=\n",
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net1.layers[1](net1.layers[0](X)) # 출력이 30이니까~ + 렐루를 거쳐서 0또는 양수인 모습!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "211506bc-2b34-4d35-9a08-1e1af5fa9253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(60000, 10), dtype=float32, numpy=\n",
       "array([[2.8995152e-21, 9.9856627e-28, 0.0000000e+00, ..., 1.2420070e-03,\n",
       "        0.0000000e+00, 9.9541569e-01],\n",
       "       [4.7701108e-01, 2.6207626e-02, 8.0454284e-03, ..., 2.3365423e-27,\n",
       "        5.3272030e-04, 4.4156360e-17],\n",
       "       [4.5070428e-01, 2.1650523e-02, 1.2756436e-02, ..., 6.4327061e-25,\n",
       "        1.0629607e-03, 1.1437141e-15],\n",
       "       ...,\n",
       "       [5.4188430e-01, 5.2440122e-02, 1.0308946e-03, ..., 1.0840898e-37,\n",
       "        2.5899959e-05, 4.3518392e-23],\n",
       "       [3.3972868e-01, 1.0773074e-02, 4.7669444e-02, ..., 2.0287354e-17,\n",
       "        8.0869868e-03, 2.4132330e-11],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 2.3465420e-05,\n",
       "        3.3327616e-09, 1.3874462e-04]], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net1.layers[2](net1.layers[1](net1.layers[0](X))) # 최종출력 10차원, 각각은 확률을 의미하게 된다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a73d015-9465-4f48-93c6-c7c65732fb00",
   "metadata": {},
   "source": [
    "`-` (참고) metrics=['accuracy'] 대신에 이렇게 해도된다~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87467e7e-95e6-4ac5-985e-725c337fc788",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 1s 667us/step - loss: 2.5321 - categorical_accuracy: 0.4089\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 1s 652us/step - loss: 1.2271 - categorical_accuracy: 0.4976\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 1s 662us/step - loss: 1.0478 - categorical_accuracy: 0.5843\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 1s 649us/step - loss: 0.9173 - categorical_accuracy: 0.6292\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 1s 650us/step - loss: 0.8538 - categorical_accuracy: 0.6457\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdf1075b3a0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(43052)\n",
    "net1 = tf.keras.Sequential()\n",
    "net1.add(tf.keras.layers.Flatten())\n",
    "net1.add(tf.keras.layers.Dense(30,activation='relu'))\n",
    "net1.add(tf.keras.layers.Dense(10,activation='softmax'))\n",
    "net1.compile(loss=tf.losses.categorical_crossentropy, optimizer='adam',metrics=[tf.metrics.CategoricalAccuracy()])\n",
    "net1.fit(X,y,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a15cc9d-d19e-4e61-91f4-97c1cfe39b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93905843608752, 93905843608752)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(tf.metrics.CategoricalAccuracy), id(tf.keras.metrics.CategoricalAccuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92b2c77-48b1-4c41-bb7b-a1cc891ae7ef",
   "metadata": {},
   "source": [
    "- 주소가 똑같네요, 이게 무슨말인지 알죠?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e6c813-c712-44cb-8ee6-aa10f32e9715",
   "metadata": {},
   "source": [
    "`-` 주의사항: tf.metrics.Accuracy() 말고 tf.metrics.CategoricalAccuracy() 를 써야함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ec372e-538a-4b0f-b6b3-cbc979a065e8",
   "metadata": {},
   "source": [
    "`-` (참고2) 메트릭을 추가할수도 있다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7906a68-0a9c-4c09-853b-5f242b7deb46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 2s 932us/step - loss: 2.5273 - categorical_accuracy: 0.4117 - recall: 0.3030\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 2s 913us/step - loss: 1.2435 - categorical_accuracy: 0.4960 - recall: 0.3858\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 2s 937us/step - loss: 1.0755 - categorical_accuracy: 0.5694 - recall: 0.4599\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 2s 919us/step - loss: 0.9960 - categorical_accuracy: 0.5975 - recall: 0.4861\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 2s 917us/step - loss: 0.8548 - categorical_accuracy: 0.6557 - recall: 0.5258\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdf1066a500>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(43052)\n",
    "net1 = tf.keras.Sequential()\n",
    "net1.add(tf.keras.layers.Flatten())\n",
    "net1.add(tf.keras.layers.Dense(30,activation='relu'))\n",
    "net1.add(tf.keras.layers.Dense(10,activation='softmax'))\n",
    "net1.compile(loss=tf.losses.categorical_crossentropy, optimizer='adam',metrics=[tf.metrics.CategoricalAccuracy(),tf.metrics.Recall()])\n",
    "net1.fit(X,y,epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300b2993-220c-47ce-a32d-64b6540e4def",
   "metadata": {},
   "source": [
    "`-` 리콜을 추가하면 test set의 성능평가에도 리콜을 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e6ed81e-c263-4762-84c5-d1339c0a5c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 835us/step - loss: 0.8248 - categorical_accuracy: 0.6813 - recall: 0.5294\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8247724771499634, 0.6812999844551086, 0.5293999910354614]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net1.evaluate(XX,yy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370ce94b-2fab-476b-85d2-839be563ffaf",
   "metadata": {},
   "source": [
    "### (예제2) X -> Dense(500,relu) -> Dense(500,relu) -> Dense(10,softmax):=>y "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d4fdfd-e49e-4b0e-8e1c-ddd38b919e0b",
   "metadata": {},
   "source": [
    "`-` 다른모형으로도 적합시켜보자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "526fd02a-7064-4978-b081-7ef8c5c3dc8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 2s 757us/step - loss: 2.2474 - accuracy: 0.7490\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 1s 765us/step - loss: 0.6386 - accuracy: 0.7904\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 1s 751us/step - loss: 0.5289 - accuracy: 0.8198\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 1s 763us/step - loss: 0.4554 - accuracy: 0.8417\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 1s 738us/step - loss: 0.4374 - accuracy: 0.8476\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdf104244c0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(43052)\n",
    "net2 = tf.keras.Sequential()\n",
    "net2.add(tf.keras.layers.Flatten())\n",
    "net2.add(tf.keras.layers.Dense(500,activation='relu'))\n",
    "net2.add(tf.keras.layers.Dense(500,activation='relu'))\n",
    "net2.add(tf.keras.layers.Dense(10,activation='softmax'))\n",
    "net2.compile(loss=tf.losses.categorical_crossentropy, optimizer='adam',metrics=['accuracy'])\n",
    "net2.fit(X,y,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "134d540a-040b-42b4-b7f0-00c406ac489d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.4716 - accuracy: 0.8356\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdf104efdf0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2.fit(XX,yy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9539c58c-5276-4956-921e-535e277dfa37",
   "metadata": {},
   "source": [
    "`-` 좀 더 돌려보자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc7210a4-3c90-435a-8b66-25d5662390ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 1s 724us/step - loss: 2.2049 - accuracy: 0.7551\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 1s 713us/step - loss: 0.6847 - accuracy: 0.7778\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 1s 722us/step - loss: 0.5943 - accuracy: 0.8036\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 1s 738us/step - loss: 0.4973 - accuracy: 0.8312\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 1s 736us/step - loss: 0.4580 - accuracy: 0.8429\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 1s 731us/step - loss: 0.4577 - accuracy: 0.8423\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 1s 738us/step - loss: 0.4241 - accuracy: 0.8521\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 1s 724us/step - loss: 0.4136 - accuracy: 0.8559\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 1s 716us/step - loss: 0.4111 - accuracy: 0.8580\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 1s 742us/step - loss: 0.4004 - accuracy: 0.8610\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdf103adb10>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(43052)\n",
    "net2 = tf.keras.Sequential()\n",
    "net2.add(tf.keras.layers.Flatten())\n",
    "net2.add(tf.keras.layers.Dense(500,activation='relu'))\n",
    "net2.add(tf.keras.layers.Dense(500,activation='relu'))\n",
    "net2.add(tf.keras.layers.Dense(10,activation='softmax'))\n",
    "net2.compile(loss=tf.losses.categorical_crossentropy, optimizer='adam',metrics=['accuracy'])\n",
    "net2.fit(X,y,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e564444-e491-4d6d-841b-41b1e258b85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.4610 - accuracy: 0.8403\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdf1026bd00>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2.fit(XX,yy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be2d785-ab47-4d2b-8470-ba1c99f64f50",
   "metadata": {},
   "source": [
    "`-` 이 이상은 비효율적인듯.. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2119bffe-a23e-422b-9111-0cec594e7664",
   "metadata": {},
   "source": [
    "## 더 좋은 모형을 만들고 싶은데.. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929ea144-a9c1-457d-bb30-88825d60502f",
   "metadata": {},
   "source": [
    "### (예제3) 아주 복잡한 DNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76f86b6-a96d-4ab2-a77b-7b1ccdcaf45a",
   "metadata": {},
   "source": [
    "`-` 아 몰라 딥러닝이 해주겠지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "02b5d10f-e71c-4adf-bc9c-7c20712e2ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.9811 - accuracy: 0.7936\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4469 - accuracy: 0.8389\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4147 - accuracy: 0.8533\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3944 - accuracy: 0.8603\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3663 - accuracy: 0.8694\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3652 - accuracy: 0.8720\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3467 - accuracy: 0.8777\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3410 - accuracy: 0.8801\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3250 - accuracy: 0.8847\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3186 - accuracy: 0.8865\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdf1011a860>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(43052)\n",
    "net3 = tf.keras.Sequential()\n",
    "net3.add(tf.keras.layers.Flatten())\n",
    "net3.add(tf.keras.layers.Dense(500,activation='relu'))\n",
    "net3.add(tf.keras.layers.Dense(500,activation='relu'))\n",
    "net3.add(tf.keras.layers.Dense(500,activation='relu'))\n",
    "net3.add(tf.keras.layers.Dense(500,activation='relu'))\n",
    "net3.add(tf.keras.layers.Dense(500,activation='relu'))\n",
    "net3.add(tf.keras.layers.Dense(10,activation='softmax'))\n",
    "net3.compile(loss=tf.losses.categorical_crossentropy, optimizer='adam',metrics=['accuracy'])\n",
    "net3.fit(X,y,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b69ac9ca-4e3f-46e0-96ce-d263bd494285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 867us/step - loss: 0.3635 - accuracy: 0.8767\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3634934723377228, 0.8766999840736389]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net3.evaluate(XX,yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "50101953-34c1-496b-85b9-4b0c8d6501f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_5 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 500)               392500    \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 500)               250500    \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                5010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 648,010\n",
      "Trainable params: 648,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "net2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "95cac1ad-079c-4933-bc8a-2f546e3fbdab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_6 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 500)               392500    \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 500)               250500    \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 500)               250500    \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 500)               250500    \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 500)               250500    \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 10)                5010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,399,510\n",
      "Trainable params: 1,399,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "net3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863fb29d-ca3d-4c55-9158-fd373249946c",
   "metadata": {},
   "source": [
    "`-` 파라메터 증가대비 그닥.. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a08785-a0dc-4f61-b31a-c94ae7b8a64b",
   "metadata": {},
   "source": [
    "`-` 왠지 DNN계열로는 한계가 있어보인다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71befde-49b2-43b0-b2b3-8f7b634a01f1",
   "metadata": {},
   "source": [
    "### 발상의 전환 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c696a03e-d3f1-4066-9879-4ddc6bed18ed",
   "metadata": {},
   "source": [
    "`-` Flattne 레이어를 보면서 느낀점: 생각해보니까 $X \\to \\hat{y}$를 만드는 과정이 꼭 Full Linear Transform(Dense layer) + Activation(Activation layer)일 필요는 없잖아?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fed118-fa77-408c-aa26-60cc3f9a4969",
   "metadata": {},
   "source": [
    "`-` 뭐가있지? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aa384c5f-19c5-4564-b108-88060cb840d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AbstractRNNCell',\n",
       " 'Activation',\n",
       " 'ActivityRegularization',\n",
       " 'Add',\n",
       " 'AdditiveAttention',\n",
       " 'AlphaDropout',\n",
       " 'Attention',\n",
       " 'Average',\n",
       " 'AveragePooling1D',\n",
       " 'AveragePooling2D',\n",
       " 'AveragePooling3D',\n",
       " 'AvgPool1D',\n",
       " 'AvgPool2D',\n",
       " 'AvgPool3D',\n",
       " 'BatchNormalization',\n",
       " 'Bidirectional',\n",
       " 'CategoryEncoding',\n",
       " 'CenterCrop',\n",
       " 'Concatenate',\n",
       " 'Conv1D',\n",
       " 'Conv1DTranspose',\n",
       " 'Conv2D',\n",
       " 'Conv2DTranspose',\n",
       " 'Conv3D',\n",
       " 'Conv3DTranspose',\n",
       " 'ConvLSTM1D',\n",
       " 'ConvLSTM2D',\n",
       " 'ConvLSTM3D',\n",
       " 'Convolution1D',\n",
       " 'Convolution1DTranspose',\n",
       " 'Convolution2D',\n",
       " 'Convolution2DTranspose',\n",
       " 'Convolution3D',\n",
       " 'Convolution3DTranspose',\n",
       " 'Cropping1D',\n",
       " 'Cropping2D',\n",
       " 'Cropping3D',\n",
       " 'Dense',\n",
       " 'DenseFeatures',\n",
       " 'DepthwiseConv1D',\n",
       " 'DepthwiseConv2D',\n",
       " 'Discretization',\n",
       " 'Dot',\n",
       " 'Dropout',\n",
       " 'ELU',\n",
       " 'Embedding',\n",
       " 'Flatten',\n",
       " 'GRU',\n",
       " 'GRUCell',\n",
       " 'GaussianDropout',\n",
       " 'GaussianNoise',\n",
       " 'GlobalAveragePooling1D',\n",
       " 'GlobalAveragePooling2D',\n",
       " 'GlobalAveragePooling3D',\n",
       " 'GlobalAvgPool1D',\n",
       " 'GlobalAvgPool2D',\n",
       " 'GlobalAvgPool3D',\n",
       " 'GlobalMaxPool1D',\n",
       " 'GlobalMaxPool2D',\n",
       " 'GlobalMaxPool3D',\n",
       " 'GlobalMaxPooling1D',\n",
       " 'GlobalMaxPooling2D',\n",
       " 'GlobalMaxPooling3D',\n",
       " 'Hashing',\n",
       " 'Input',\n",
       " 'InputLayer',\n",
       " 'InputSpec',\n",
       " 'IntegerLookup',\n",
       " 'LSTM',\n",
       " 'LSTMCell',\n",
       " 'Lambda',\n",
       " 'Layer',\n",
       " 'LayerNormalization',\n",
       " 'LeakyReLU',\n",
       " 'LocallyConnected1D',\n",
       " 'LocallyConnected2D',\n",
       " 'Masking',\n",
       " 'MaxPool1D',\n",
       " 'MaxPool2D',\n",
       " 'MaxPool3D',\n",
       " 'MaxPooling1D',\n",
       " 'MaxPooling2D',\n",
       " 'MaxPooling3D',\n",
       " 'Maximum',\n",
       " 'Minimum',\n",
       " 'MultiHeadAttention',\n",
       " 'Multiply',\n",
       " 'Normalization',\n",
       " 'PReLU',\n",
       " 'Permute',\n",
       " 'RNN',\n",
       " 'RandomContrast',\n",
       " 'RandomCrop',\n",
       " 'RandomFlip',\n",
       " 'RandomHeight',\n",
       " 'RandomRotation',\n",
       " 'RandomTranslation',\n",
       " 'RandomWidth',\n",
       " 'RandomZoom',\n",
       " 'ReLU',\n",
       " 'RepeatVector',\n",
       " 'Rescaling',\n",
       " 'Reshape',\n",
       " 'Resizing',\n",
       " 'SeparableConv1D',\n",
       " 'SeparableConv2D',\n",
       " 'SeparableConvolution1D',\n",
       " 'SeparableConvolution2D',\n",
       " 'SimpleRNN',\n",
       " 'SimpleRNNCell',\n",
       " 'Softmax',\n",
       " 'SpatialDropout1D',\n",
       " 'SpatialDropout2D',\n",
       " 'SpatialDropout3D',\n",
       " 'StackedRNNCells',\n",
       " 'StringLookup',\n",
       " 'Subtract',\n",
       " 'TextVectorization',\n",
       " 'ThresholdedReLU',\n",
       " 'TimeDistributed',\n",
       " 'UpSampling1D',\n",
       " 'UpSampling2D',\n",
       " 'UpSampling3D',\n",
       " 'Wrapper',\n",
       " 'ZeroPadding1D',\n",
       " 'ZeroPadding2D',\n",
       " 'ZeroPadding3D',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_sys',\n",
       " 'add',\n",
       " 'average',\n",
       " 'concatenate',\n",
       " 'deserialize',\n",
       " 'dot',\n",
       " 'experimental',\n",
       " 'maximum',\n",
       " 'minimum',\n",
       " 'multiply',\n",
       " 'serialize',\n",
       " 'subtract']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(tf.keras.layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ac10ab-7559-4c58-8e35-d530d7dce463",
   "metadata": {},
   "source": [
    "`-` 엄청많아.. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63f619f-cb92-4075-810b-92aa11e06c70",
   "metadata": {},
   "source": [
    "`-` 우리는 이중에서 2D conv, max pooling 에 관심이 있다! (이번수업은 max pooling 정도만)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a067ccd6-c170-426d-89ea-d2273be38dd1",
   "metadata": {},
   "source": [
    "#### MaxPooling2D, MaxPool2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a35c44c0-7254-4146-8a20-1bddabb95c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93905842676320, 93905842676320)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(tf.keras.layers.MaxPooling2D), id(tf.keras.layers.MaxPool2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b100e40b-a617-46c2-ac30-e63d9ed7b02f",
   "metadata": {},
   "source": [
    "`-` 테스트1: (2,2) 이미지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "043c086c-fd8c-491b-965d-5fc2516db672",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp = tf.keras.layers.MaxPool2D() # pool size의 디폴트는 (2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dbf93ac7-f1f0-4dee-ba61-fc1c7227dc43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2, 2, 1), dtype=int64, numpy=\n",
       "array([[[[0],\n",
       "         [1]],\n",
       "\n",
       "        [[2],\n",
       "         [3]]]])>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XXX = tnp.arange(1*2*2*1).reshape(1,2,2,1)\n",
    "XXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "522bae91-436e-4cc1-9d1f-3a167cc4d138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2, 2), dtype=int64, numpy=\n",
       "array([[[0, 1],\n",
       "        [2, 3]]])>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XXX.reshape(1,2,2) # 채널때문에 살짝 헷갈리지만 실제로는 이렇게 생긴 이미지! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "43a49b37-98d2-47c9-a7e6-4e27170a0d13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1, 1, 1), dtype=int64, numpy=array([[[[3]]]])>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp(XXX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13c0ce4-4c45-425e-b6bc-ba8f0d4ab53e",
   "metadata": {},
   "source": [
    "`-` 테스트2: (4,4) 이미지로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a14d0f44-d754-4c02-880c-02e783b1e773",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp = tf.keras.layers.MaxPool2D() # pool size의 디폴트는 (2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8945422d-4f9b-4884-babb-fc555c682754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 4, 4, 1), dtype=int64, numpy=\n",
       " array([[[[ 0],\n",
       "          [ 1],\n",
       "          [ 2],\n",
       "          [ 3]],\n",
       " \n",
       "         [[ 4],\n",
       "          [ 5],\n",
       "          [ 6],\n",
       "          [ 7]],\n",
       " \n",
       "         [[ 8],\n",
       "          [ 9],\n",
       "          [10],\n",
       "          [11]],\n",
       " \n",
       "         [[12],\n",
       "          [13],\n",
       "          [14],\n",
       "          [15]]]])>,\n",
       " <tf.Tensor: shape=(1, 4, 4), dtype=int64, numpy=\n",
       " array([[[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11],\n",
       "         [12, 13, 14, 15]]])>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XXX = tnp.arange(1*4*4*1).reshape(1,4,4,1)\n",
    "XXX,XXX.reshape(1,4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0cfba977-20bd-49c9-a2a0-f815b343a374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 2, 2, 1), dtype=int64, numpy=\n",
       " array([[[[ 5],\n",
       "          [ 7]],\n",
       " \n",
       "         [[13],\n",
       "          [15]]]])>,\n",
       " <tf.Tensor: shape=(1, 2, 2), dtype=int64, numpy=\n",
       " array([[[ 5,  7],\n",
       "         [13, 15]]])>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp(XXX),mp(XXX).reshape(1,2,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0fca84-bb19-4555-9d12-3103af3c6fc9",
   "metadata": {},
   "source": [
    "`-` 테스트3: (6,6) 이미지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2354d1d8-cd1b-4b97-be39-2200cb38d121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 6, 6), dtype=int64, numpy=\n",
       "array([[[ 0,  1,  2,  3,  4,  5],\n",
       "        [ 6,  7,  8,  9, 10, 11],\n",
       "        [12, 13, 14, 15, 16, 17],\n",
       "        [18, 19, 20, 21, 22, 23],\n",
       "        [24, 25, 26, 27, 28, 29],\n",
       "        [30, 31, 32, 33, 34, 35]]])>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XXX = tnp.arange(1*6*6*1).reshape(1,6,6,1)\n",
    "XXX.reshape(1,6,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a46157bd-1725-4e6c-a363-4227f97d6785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3, 3), dtype=int64, numpy=\n",
       "array([[[ 7,  9, 11],\n",
       "        [19, 21, 23],\n",
       "        [31, 33, 35]]])>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp(XXX).reshape(1,3,3) # 왜 (2,2)씩...? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2dd3f78-33b7-4479-92d7-02c0c942694f",
   "metadata": {},
   "source": [
    "`-` 테스트4: (6,6) 이미지 + pool_size=(3, 3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "20148704-7d26-448e-849d-64f610963bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2, 2), dtype=int64, numpy=\n",
       "array([[[14, 17],\n",
       "        [32, 35]]])>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp3 = tf.keras.layers.MaxPool2D(pool_size=(3,3))\n",
    "mp3(XXX).reshape(1,2,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ec9b93-1b13-416e-a56b-3051d613d8a6",
   "metadata": {},
   "source": [
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef6b06e-168b-40a5-bcc6-fc516b07c3ce",
   "metadata": {},
   "source": [
    "이 부분은 5월11일 강의에서 추가된 내용입니다. 설명은 5월11일 영상을 참고하세요 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84c577c-f9d1-4e68-9180-ef8663a6bba1",
   "metadata": {},
   "source": [
    "`-` 테스트5: 관측치증가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "113b7cb4-3147-46bf-90cc-a2d1d3318c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 4, 4), dtype=int64, numpy=\n",
       "array([[[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11],\n",
       "        [12, 13, 14, 15]],\n",
       "\n",
       "       [[16, 17, 18, 19],\n",
       "        [20, 21, 22, 23],\n",
       "        [24, 25, 26, 27],\n",
       "        [28, 29, 30, 31]]])>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XXX = tnp.arange(2*4*4*1).reshape(2,4,4,1)\n",
    "XXX.reshape(2,4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e021b209-d596-47a1-8244-b396a3514d67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 2), dtype=int64, numpy=\n",
       "array([[[ 5,  7],\n",
       "        [13, 15]],\n",
       "\n",
       "       [[21, 23],\n",
       "        [29, 31]]])>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp(XXX).reshape(2,2,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c5da9d-8c30-4978-b2ea-0f129b28f208",
   "metadata": {},
   "source": [
    "`-` 테스트6: 채널증가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bd01625-acfe-4e28-b51f-9c83bf0838ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4, 4, 3), dtype=int64, numpy=\n",
       "array([[[[ 0,  1,  2],\n",
       "         [ 3,  4,  5],\n",
       "         [ 6,  7,  8],\n",
       "         [ 9, 10, 11]],\n",
       "\n",
       "        [[12, 13, 14],\n",
       "         [15, 16, 17],\n",
       "         [18, 19, 20],\n",
       "         [21, 22, 23]],\n",
       "\n",
       "        [[24, 25, 26],\n",
       "         [27, 28, 29],\n",
       "         [30, 31, 32],\n",
       "         [33, 34, 35]],\n",
       "\n",
       "        [[36, 37, 38],\n",
       "         [39, 40, 41],\n",
       "         [42, 43, 44],\n",
       "         [45, 46, 47]]]])>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XXX = tnp.arange(1*4*4*3).reshape(1,4,4,3)\n",
    "XXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d3771e7-5359-4814-be03-32767e4bc53b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4, 4), dtype=int64, numpy=\n",
       "array([[[ 0,  3,  6,  9],\n",
       "        [12, 15, 18, 21],\n",
       "        [24, 27, 30, 33],\n",
       "        [36, 39, 42, 45]]])>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XXX[...,0] # XXX[:,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa9fd416-a3c9-4300-858e-94822608878a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 4, 4), dtype=int64, numpy=\n",
       " array([[[ 0,  3,  6,  9],\n",
       "         [12, 15, 18, 21],\n",
       "         [24, 27, 30, 33],\n",
       "         [36, 39, 42, 45]]])>,\n",
       " <tf.Tensor: shape=(1, 4, 4), dtype=int64, numpy=\n",
       " array([[[ 1,  4,  7, 10],\n",
       "         [13, 16, 19, 22],\n",
       "         [25, 28, 31, 34],\n",
       "         [37, 40, 43, 46]]])>,\n",
       " <tf.Tensor: shape=(1, 4, 4), dtype=int64, numpy=\n",
       " array([[[ 2,  5,  8, 11],\n",
       "         [14, 17, 20, 23],\n",
       "         [26, 29, 32, 35],\n",
       "         [38, 41, 44, 47]]])>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XXX1 = XXX[...,0]\n",
    "XXX2 = XXX[...,1]\n",
    "XXX3 = XXX[...,2]\n",
    "XXX1,XXX2,XXX3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6db6b2da-7fe2-44a5-9b8f-081e6ef00a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "YYY1 = mp(XXX)[...,0]\n",
    "YYY2 = mp(XXX)[...,1]\n",
    "YYY3 = mp(XXX)[...,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a6086368-583a-4d6d-8d38-0ae4405e282c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 2, 2), dtype=int64, numpy=\n",
       " array([[[15, 21],\n",
       "         [39, 45]]])>,\n",
       " <tf.Tensor: shape=(1, 2, 2), dtype=int64, numpy=\n",
       " array([[[16, 22],\n",
       "         [40, 46]]])>,\n",
       " <tf.Tensor: shape=(1, 2, 2), dtype=int64, numpy=\n",
       " array([[[17, 23],\n",
       "         [41, 47]]])>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YYY1,YYY2,YYY3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d11a61-eda9-48da-924c-5da503d6816e",
   "metadata": {},
   "source": [
    "- 관측치와 채널은 처음에만 따져보고 외울때는 1observation/흑백 버전만 고려해도 무방! (나머지는 복붙이니까)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0627a519-53d1-44d7-b436-bc50cfc1fbf9",
   "metadata": {},
   "source": [
    "`-` 테스트7: 숫자가 좀 안맞으면?... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "242a8f15-9a98-4c83-92a3-d770f596ae98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 5, 5), dtype=int64, numpy=\n",
       "array([[[  0,  -1,  -2,  -3,  -4],\n",
       "        [ -5,  -6,  -7,  -8,  -9],\n",
       "        [-10, -11, -12, -13, -14],\n",
       "        [-15, -16, -17, -18, -19],\n",
       "        [-20, -21, -22, -23, -24]]])>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XXX = - tnp.arange(1*5*5*1).reshape(1,5,5,1)\n",
    "XXX.reshape(1,5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee514d15-8bf1-45ca-9b4f-f97315a0358b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2, 2), dtype=int64, numpy=\n",
       "array([[[  0,  -2],\n",
       "        [-10, -12]]])>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp(XXX).reshape(1,2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e17eebd-f951-42e9-bd8e-183bbefca10f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPool2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Max pooling operation for 2D spatial data.\n",
       "\n",
       "Downsamples the input along its spatial dimensions (height and width)\n",
       "by taking the maximum value over an input window\n",
       "(of size defined by `pool_size`) for each channel of the input.\n",
       "The window is shifted by `strides` along each dimension.\n",
       "\n",
       "The resulting output,\n",
       "when using the `\"valid\"` padding option, has a spatial shape\n",
       "(number of rows or columns) of:\n",
       "`output_shape = math.floor((input_shape - pool_size) / strides) + 1`\n",
       "(when `input_shape >= pool_size`)\n",
       "\n",
       "The resulting output shape when using the `\"same\"` padding option is:\n",
       "`output_shape = math.floor((input_shape - 1) / strides) + 1`\n",
       "\n",
       "For example, for `strides=(1, 1)` and `padding=\"valid\"`:\n",
       "\n",
       ">>> x = tf.constant([[1., 2., 3.],\n",
       "...                  [4., 5., 6.],\n",
       "...                  [7., 8., 9.]])\n",
       ">>> x = tf.reshape(x, [1, 3, 3, 1])\n",
       ">>> max_pool_2d = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),\n",
       "...    strides=(1, 1), padding='valid')\n",
       ">>> max_pool_2d(x)\n",
       "<tf.Tensor: shape=(1, 2, 2, 1), dtype=float32, numpy=\n",
       "  array([[[[5.],\n",
       "           [6.]],\n",
       "          [[8.],\n",
       "           [9.]]]], dtype=float32)>\n",
       "\n",
       "For example, for `strides=(2, 2)` and `padding=\"valid\"`:\n",
       "\n",
       ">>> x = tf.constant([[1., 2., 3., 4.],\n",
       "...                  [5., 6., 7., 8.],\n",
       "...                  [9., 10., 11., 12.]])\n",
       ">>> x = tf.reshape(x, [1, 3, 4, 1])\n",
       ">>> max_pool_2d = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),\n",
       "...    strides=(2, 2), padding='valid')\n",
       ">>> max_pool_2d(x)\n",
       "<tf.Tensor: shape=(1, 1, 2, 1), dtype=float32, numpy=\n",
       "  array([[[[6.],\n",
       "           [8.]]]], dtype=float32)>\n",
       "\n",
       "Usage Example:\n",
       "\n",
       ">>> input_image = tf.constant([[[[1.], [1.], [2.], [4.]],\n",
       "...                            [[2.], [2.], [3.], [2.]],\n",
       "...                            [[4.], [1.], [1.], [1.]],\n",
       "...                            [[2.], [2.], [1.], [4.]]]])\n",
       ">>> output = tf.constant([[[[1], [0]],\n",
       "...                       [[0], [1]]]])\n",
       ">>> model = tf.keras.models.Sequential()\n",
       ">>> model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2),\n",
       "...    input_shape=(4, 4, 1)))\n",
       ">>> model.compile('adam', 'mean_squared_error')\n",
       ">>> model.predict(input_image, steps=1)\n",
       "array([[[[2.],\n",
       "         [4.]],\n",
       "        [[4.],\n",
       "         [4.]]]], dtype=float32)\n",
       "\n",
       "For example, for stride=(1, 1) and padding=\"same\":\n",
       "\n",
       ">>> x = tf.constant([[1., 2., 3.],\n",
       "...                  [4., 5., 6.],\n",
       "...                  [7., 8., 9.]])\n",
       ">>> x = tf.reshape(x, [1, 3, 3, 1])\n",
       ">>> max_pool_2d = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),\n",
       "...    strides=(1, 1), padding='same')\n",
       ">>> max_pool_2d(x)\n",
       "<tf.Tensor: shape=(1, 3, 3, 1), dtype=float32, numpy=\n",
       "  array([[[[5.],\n",
       "           [6.],\n",
       "           [6.]],\n",
       "          [[8.],\n",
       "           [9.],\n",
       "           [9.]],\n",
       "          [[8.],\n",
       "           [9.],\n",
       "           [9.]]]], dtype=float32)>\n",
       "\n",
       "Args:\n",
       "  pool_size: integer or tuple of 2 integers,\n",
       "    window size over which to take the maximum.\n",
       "    `(2, 2)` will take the max value over a 2x2 pooling window.\n",
       "    If only one integer is specified, the same window length\n",
       "    will be used for both dimensions.\n",
       "  strides: Integer, tuple of 2 integers, or None.\n",
       "    Strides values.  Specifies how far the pooling window moves\n",
       "    for each pooling step. If None, it will default to `pool_size`.\n",
       "  padding: One of `\"valid\"` or `\"same\"` (case-insensitive).\n",
       "    `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n",
       "    the left/right or up/down of the input such that output has the same\n",
       "    height/width dimension as the input.\n",
       "  data_format: A string,\n",
       "    one of `channels_last` (default) or `channels_first`.\n",
       "    The ordering of the dimensions in the inputs.\n",
       "    `channels_last` corresponds to inputs with shape\n",
       "    `(batch, height, width, channels)` while `channels_first`\n",
       "    corresponds to inputs with shape\n",
       "    `(batch, channels, height, width)`.\n",
       "    It defaults to the `image_data_format` value found in your\n",
       "    Keras config file at `~/.keras/keras.json`.\n",
       "    If you never set it, then it will be \"channels_last\".\n",
       "\n",
       "Input shape:\n",
       "  - If `data_format='channels_last'`:\n",
       "    4D tensor with shape `(batch_size, rows, cols, channels)`.\n",
       "  - If `data_format='channels_first'`:\n",
       "    4D tensor with shape `(batch_size, channels, rows, cols)`.\n",
       "\n",
       "Output shape:\n",
       "  - If `data_format='channels_last'`:\n",
       "    4D tensor with shape `(batch_size, pooled_rows, pooled_cols, channels)`.\n",
       "  - If `data_format='channels_first'`:\n",
       "    4D tensor with shape `(batch_size, channels, pooled_rows, pooled_cols)`.\n",
       "\n",
       "Returns:\n",
       "  A tensor of rank 4 representing the maximum pooled values.  See above for\n",
       "  output shape.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/anaconda3/envs/tfgpu/lib/python3.10/site-packages/keras/layers/pooling.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     MaxPooling2D\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.keras.layers.MaxPool2D?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d946cc00-7dc9-4a4e-8b82-5cf0684564ef",
   "metadata": {},
   "source": [
    "- https://keras.io/api/layers/convolution_layers/convolution2d/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f416937c-454f-4f47-aa43-4f1b33f233d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp = tf.keras.layers.MaxPool2D(padding='same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "31348474-907f-4f2c-859b-f296736c2fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3, 3), dtype=int64, numpy=\n",
       "array([[[  0,  -2,  -4],\n",
       "        [-10, -12, -14],\n",
       "        [-20, -22, -24]]])>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp(XXX).reshape(1,3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "babe64cd-20c4-4872-838d-79ee5001bed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 5, 5), dtype=int64, numpy=\n",
       "array([[[  0,  -1,  -2,  -3,  -4],\n",
       "        [ -5,  -6,  -7,  -8,  -9],\n",
       "        [-10, -11, -12, -13, -14],\n",
       "        [-15, -16, -17, -18, -19],\n",
       "        [-20, -21, -22, -23, -24]]])>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XXX.reshape(1,5,5)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
