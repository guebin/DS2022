{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e00653f7-3571-4b63-84ea-e46b61b173cb",
   "metadata": {},
   "source": [
    "# 5월16일"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4279e7-0990-4c92-bc2c-2a71acbafb36",
   "metadata": {},
   "source": [
    "## 강의영상 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f9be08-9f0f-4d6b-ab2b-46713ef700c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d96d526b-eff1-47a3-9081-22877e608495",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import tensorflow.experimental.numpy as tnp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2acae176-82a9-4d34-a64c-4fa0f708bf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f97610fd-4ffd-4167-a7d1-8b56773472bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.experimental.numpy.experimental_enable_numpy_behavior()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad517b7-5252-42f2-a0c8-a2e3deba5e63",
   "metadata": {},
   "source": [
    "## Conv2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2349dd-155d-4c61-b99d-c0c62b4e10a7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78bc184a-7eb6-47a9-9429-52a72009b5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2d=tf.keras.layers.Conv2D(1,(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da44df0c-2af8-4050-bb86-b62575164ef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4, 4, 1), dtype=float64, numpy=\n",
       "array([[[[ 0.],\n",
       "         [ 1.],\n",
       "         [ 2.],\n",
       "         [ 3.]],\n",
       "\n",
       "        [[ 4.],\n",
       "         [ 5.],\n",
       "         [ 6.],\n",
       "         [ 7.]],\n",
       "\n",
       "        [[ 8.],\n",
       "         [ 9.],\n",
       "         [10.],\n",
       "         [11.]],\n",
       "\n",
       "        [[12.],\n",
       "         [13.],\n",
       "         [14.],\n",
       "         [15.]]]])>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XXX= tnp.arange(1*4*4*1,dtype=tf.float64).reshape(1,4,4,1)\n",
    "XXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d015c8ae-3536-491f-a55e-c0036ca704c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3, 3, 1), dtype=float32, numpy=\n",
       "array([[[[ 1.9133414],\n",
       "         [ 3.3166614],\n",
       "         [ 4.719981 ]],\n",
       "\n",
       "        [[ 7.526621 ],\n",
       "         [ 8.92994  ],\n",
       "         [10.333261 ]],\n",
       "\n",
       "        [[13.139901 ],\n",
       "         [14.543221 ],\n",
       "         [15.946542 ]]]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d(XXX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ed626a-022d-4133-9bf6-d4b2640b1f99",
   "metadata": {},
   "source": [
    "`-` 에러가 생기는경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "428f37cd-47e9-4dd2-9c50-68bf9b303d2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4, 4), dtype=float64, numpy=\n",
       "array([[[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5.,  6.,  7.],\n",
       "        [ 8.,  9., 10., 11.],\n",
       "        [12., 13., 14., 15.]]])>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XXX= tnp.arange(1*4*4,dtype=tf.float64).reshape(1,4,4)\n",
    "XXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50978401-a814-4ce7-8a28-7e6e34a3c46c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"conv2d\" is incompatible with the layer: expected min_ndim=4, found ndim=3. Full shape received: (1, 4, 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXXX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.10/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.10/site-packages/keras/engine/input_spec.py:227\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    225\u001b[0m   ndim \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mrank\n\u001b[1;32m    226\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m ndim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m ndim \u001b[38;5;241m<\u001b[39m spec\u001b[38;5;241m.\u001b[39mmin_ndim:\n\u001b[0;32m--> 227\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    228\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis incompatible with the layer: \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    229\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpected min_ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mmin_ndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    230\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfound ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    231\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFull shape received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(shape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    232\u001b[0m \u001b[38;5;66;03m# Check dtype.\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"conv2d\" is incompatible with the layer: expected min_ndim=4, found ndim=3. Full shape received: (1, 4, 4)"
     ]
    }
   ],
   "source": [
    "conv2d(XXX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a6f385b-68ab-4248-afdc-8fd490b97d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4, 4, 1), dtype=int64, numpy=\n",
       "array([[[[ 0],\n",
       "         [ 1],\n",
       "         [ 2],\n",
       "         [ 3]],\n",
       "\n",
       "        [[ 4],\n",
       "         [ 5],\n",
       "         [ 6],\n",
       "         [ 7]],\n",
       "\n",
       "        [[ 8],\n",
       "         [ 9],\n",
       "         [10],\n",
       "         [11]],\n",
       "\n",
       "        [[12],\n",
       "         [13],\n",
       "         [14],\n",
       "         [15]]]])>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XXX= tnp.arange(1*4*4*1).reshape(1,4,4,1)\n",
    "XXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7432de6d-d882-4db1-9657-d280a54233b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Exception encountered when calling layer \"conv2d\" (type Conv2D).\n\nValue for attr 'T' of int64 is not in the list of allowed values: half, bfloat16, float, double, int32\n\t; NodeDef: {{node Conv2D}}; Op<name=Conv2D; signature=input:T, filter:T -> output:T; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE, DT_INT32]; attr=strides:list(int); attr=use_cudnn_on_gpu:bool,default=true; attr=padding:string,allowed=[\"SAME\", \"VALID\", \"EXPLICIT\"]; attr=explicit_paddings:list(int),default=[]; attr=data_format:string,default=\"NHWC\",allowed=[\"NHWC\", \"NCHW\"]; attr=dilations:list(int),default=[1, 1, 1, 1]> [Op:Conv2D]\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(1, 4, 4, 1), dtype=int64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXXX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.10/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:7107\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7105\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   7106\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 7107\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Exception encountered when calling layer \"conv2d\" (type Conv2D).\n\nValue for attr 'T' of int64 is not in the list of allowed values: half, bfloat16, float, double, int32\n\t; NodeDef: {{node Conv2D}}; Op<name=Conv2D; signature=input:T, filter:T -> output:T; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE, DT_INT32]; attr=strides:list(int); attr=use_cudnn_on_gpu:bool,default=true; attr=padding:string,allowed=[\"SAME\", \"VALID\", \"EXPLICIT\"]; attr=explicit_paddings:list(int),default=[]; attr=data_format:string,default=\"NHWC\",allowed=[\"NHWC\", \"NCHW\"]; attr=dilations:list(int),default=[1, 1, 1, 1]> [Op:Conv2D]\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(1, 4, 4, 1), dtype=int64)"
     ]
    }
   ],
   "source": [
    "conv2d(XXX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ee2e98-76b7-4326-923b-ec3ef7f57565",
   "metadata": {},
   "source": [
    "`-` float16,32,64는 에러가 나지 않음 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56fc1a5a-1f7f-4828-beeb-78b9fc128fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3, 3, 1), dtype=float32, numpy=\n",
       "array([[[[ 1.9133414],\n",
       "         [ 3.3166614],\n",
       "         [ 4.719981 ]],\n",
       "\n",
       "        [[ 7.526621 ],\n",
       "         [ 8.92994  ],\n",
       "         [10.333261 ]],\n",
       "\n",
       "        [[13.139901 ],\n",
       "         [14.543221 ],\n",
       "         [15.946542 ]]]], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XXX= tnp.arange(1*4*4*1,dtype=tf.float16).reshape(1,4,4,1)\n",
    "conv2d(XXX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e173a9c-3aff-4218-9c1b-eb60a28d3431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3, 3, 1), dtype=float32, numpy=\n",
       "array([[[[ 1.9133414],\n",
       "         [ 3.3166614],\n",
       "         [ 4.719981 ]],\n",
       "\n",
       "        [[ 7.526621 ],\n",
       "         [ 8.92994  ],\n",
       "         [10.333261 ]],\n",
       "\n",
       "        [[13.139901 ],\n",
       "         [14.543221 ],\n",
       "         [15.946542 ]]]], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XXX= tnp.arange(1*4*4*1,dtype=tf.float32).reshape(1,4,4,1)\n",
    "conv2d(XXX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0d8cb5d-229c-42a0-b03c-d93492b7cd6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3, 3, 1), dtype=float32, numpy=\n",
       "array([[[[ 1.9133414],\n",
       "         [ 3.3166614],\n",
       "         [ 4.719981 ]],\n",
       "\n",
       "        [[ 7.526621 ],\n",
       "         [ 8.92994  ],\n",
       "         [10.333261 ]],\n",
       "\n",
       "        [[13.139901 ],\n",
       "         [14.543221 ],\n",
       "         [15.946542 ]]]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XXX= tnp.arange(1*4*4*1,dtype=tf.float64).reshape(1,4,4,1)\n",
    "conv2d(XXX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05234220-c3b9-4edb-836e-246ea58e0c0c",
   "metadata": {},
   "source": [
    "### test1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69301ea2-ac8f-4dd1-bd8b-0f09e65bf822",
   "metadata": {},
   "source": [
    "`-` 첫시도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a03a4a1a-cf9c-4f59-9126-ea9b2b710755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4, 4), dtype=float64, numpy=\n",
       "array([[[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5.,  6.,  7.],\n",
       "        [ 8.,  9., 10., 11.],\n",
       "        [12., 13., 14., 15.]]])>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XXX= tnp.arange(1*4*4*1,dtype=tf.float64).reshape(1,4,4,1)\n",
    "XXX.reshape(1,4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2139a60-27a1-43c1-9611-e301ea1853bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=\n",
       "array([[[ 1.9133414,  3.3166614,  4.719981 ],\n",
       "        [ 7.526621 ,  8.92994  , 10.333261 ],\n",
       "        [13.139901 , 14.543221 , 15.946542 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d(XXX).reshape(1,3,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddaea9d8-150e-4248-9b4d-72c1edd2dde9",
   "metadata": {},
   "source": [
    "- XXX에서 conv2d(XXX)로 가는 규칙이 무엇일까? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7155a0e-5ebd-4772-a24a-ea6889b23503",
   "metadata": {},
   "source": [
    "`-` 코드의정리 -> 랜덤으로 바뀌는 부분이 있어서 seed고정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9a94d4e3-350e-4eee-b778-36a3650cf67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(43052)\n",
    "XXX= tnp.arange(1*4*4*1,dtype=tf.float64).reshape(1,4,4,1)\n",
    "conv2d = tf.keras.layers.Conv2D(1,(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8f61ef03-978b-4662-ac51-77605f19d711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0.  1.  2.  3.]\n",
      "  [ 4.  5.  6.  7.]\n",
      "  [ 8.  9. 10. 11.]\n",
      "  [12. 13. 14. 15.]]], shape=(1, 4, 4), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[[ -4.125754   -5.312817   -6.4998803]\n",
      "  [ -8.874006  -10.0610695 -11.248133 ]\n",
      "  [-13.622259  -14.809322  -15.996386 ]]], shape=(1, 3, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(XXX.reshape(1,4,4))\n",
    "print(conv2d(XXX).reshape(1,3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "394888f4-f2f6-44a8-a4e7-b29e4a95fbb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[-0.13014299, -0.23927206],\n",
       "       [-0.20175874, -0.6158894 ]], dtype=float32)>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(conv2d.weights[0],(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d95f15b1-4097-455d-889f-78aa83e0fad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.1257540200000005"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0 * -0.13014299 + 1 * -0.23927206 + 4 * -0.20175874 + 5 * -0.6158894"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8170bdb-0317-4835-9669-10091d026aac",
   "metadata": {},
   "source": [
    "`-` 결과 관찰하는 것이 힘드니까 에이트를 조정해보자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "32e38d7a-6d02-465b-925d-4854129b29ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[[-0.13014299]],\n",
       " \n",
       "         [[-0.23927206]]],\n",
       " \n",
       " \n",
       "        [[[-0.20175874]],\n",
       " \n",
       "         [[-0.6158894 ]]]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e5940823-985e-41d5-908a-3b401edf00c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2, 1, 1)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d.get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0c2517d2-b069-45fd-b8f0-20b234b69ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "w= np.array([1/4,1/4,1/4,1/4],dtype=np.float32).reshape(2,2,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "afb587a9-0003-4986-9f41-07a89f7cc6d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d.get_weights()[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ebd1282a-7cb6-44ee-bccd-3f4832ec1a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "b= np.array([3],dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3687787a-4678-42e1-b745-00dc4d37455d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2d.set_weights([w,b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6ef89bee-bf8b-4981-8e49-7b728d4fb4db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[[0.25]],\n",
       " \n",
       "         [[0.25]]],\n",
       " \n",
       " \n",
       "        [[[0.25]],\n",
       " \n",
       "         [[0.25]]]], dtype=float32),\n",
       " array([3.], dtype=float32)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0233aecd-6f71-47cc-889c-77ce3ade929f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0.  1.  2.  3.]\n",
      "  [ 4.  5.  6.  7.]\n",
      "  [ 8.  9. 10. 11.]\n",
      "  [12. 13. 14. 15.]]], shape=(1, 4, 4), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[[ 5.5  6.5  7.5]\n",
      "  [ 9.5 10.5 11.5]\n",
      "  [13.5 14.5 15.5]]], shape=(1, 3, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(XXX.reshape(1,4,4))\n",
    "print(conv2d(XXX).reshape(1,3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9eb9807e-ac41-4e1a-a3c8-dca647b11672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.5, 6.5, 7.5)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0+1+4+5)/4 +3, (1+2+5+6)/4 +3, (2+3+6+7)/4 +3 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145a3e73-9358-48c4-87f0-7f86c9cd0003",
   "metadata": {},
   "source": [
    "### tf.keras.layers.Conv2D(1,kernel_size=(2,2)) 요약"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2789ffc1-9216-49fe-9cc6-86de4f7724c0",
   "metadata": {},
   "source": [
    "`-` 요약"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03c7635-e951-4db8-bd92-3a545cef0eb4",
   "metadata": {},
   "source": [
    "(1) size=(2,2)인 윈도우를 만듬. \n",
    "\n",
    "(2) XXX에 윈도우를 통과시켜서 (2,2)크기의 sub XXX 를 얻음. sub XXX의 각 원소에 conv2d.weights[0]의 각 원소를 element-wise하게 곱한다. \n",
    "\n",
    "(3) (2)의 결과를 모두 더한다. 그리고 그 결과에 다시 conv2d.weights[1]을 수행 \n",
    "\n",
    "(4) 윈도우를 이동시키면서 반복!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6723cd-2db2-4210-8a7a-58a59c6ffd76",
   "metadata": {},
   "source": [
    "### test2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c27bb4-9f8f-4ba3-847d-f8bcb0e3edfd",
   "metadata": {},
   "source": [
    "`-` XXX의 관측치가 여러개라면? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5497335a-6a42-4b3c-a02d-ff5507ddb8e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 4, 4), dtype=float64, numpy=\n",
       "array([[[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5.,  6.,  7.],\n",
       "        [ 8.,  9., 10., 11.],\n",
       "        [12., 13., 14., 15.]],\n",
       "\n",
       "       [[16., 17., 18., 19.],\n",
       "        [20., 21., 22., 23.],\n",
       "        [24., 25., 26., 27.],\n",
       "        [28., 29., 30., 31.]]])>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XXX = tnp.arange(2*4*4*1,dtype=tf.float64).reshape(2,4,4,1)\n",
    "XXX.reshape(2,4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3814a1d2-9464-4c1b-aeff-e3ddbb08781f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 3), dtype=float32, numpy=\n",
       "array([[[ 5.5,  6.5,  7.5],\n",
       "        [ 9.5, 10.5, 11.5],\n",
       "        [13.5, 14.5, 15.5]],\n",
       "\n",
       "       [[21.5, 22.5, 23.5],\n",
       "        [25.5, 26.5, 27.5],\n",
       "        [29.5, 30.5, 31.5]]], dtype=float32)>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d(XXX).reshape(2,3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "88aaa711-3343-4ebd-8c83-cf5a544fe26f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.5"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(16+17+20+21)/4 + 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b2b7e8-6fe6-48fb-996c-19d6207bbd32",
   "metadata": {
    "tags": []
   },
   "source": [
    "### test3 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dec608-c3af-415d-9d1d-dc37d44f8690",
   "metadata": {},
   "source": [
    "`-` 윈도우의 크기가 (3,3)이라면? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8d4f5109-d2e4-4c27-8839-a1992c720614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4, 4), dtype=float64, numpy=\n",
       "array([[[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]]])>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XXX = tnp.array([1]*1*4*4*1,dtype=tf.float64).reshape(1,4,4,1)\n",
    "XXX.reshape(1,4,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440f9394-14f4-4e50-9b2b-30947459aa9c",
   "metadata": {},
   "source": [
    "- 이렇게하면 conv의 결과과 weight의 sum이 나오므로 확인하기 쉽다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "001b5522-f5e3-4f3d-bcc3-6cc2d0f0e424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2, 2), dtype=float32, numpy=\n",
       "array([[[1.7760725, 1.7760725],\n",
       "        [1.7760725, 1.7760725]]], dtype=float32)>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d = tf.keras.layers.Conv2D(1,(3,3))\n",
    "conv2d(XXX).reshape(1,2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ac77a21e-81ce-4cc4-b817-aaef70c608f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1.7760723>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(tf.reshape(conv2d.weights[0],(3,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2ec0e2-6d73-47bb-9fc1-d31797446bde",
   "metadata": {},
   "source": [
    "### test4 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cacab5-3b59-4ecf-8c02-0dc19c71ba54",
   "metadata": {},
   "source": [
    "![](https://github.com/guebin/2021BDA/blob/master/_notebooks/2021-11-04-conv.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "637bd425-a229-44dc-bdf2-30a6709eb63c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 5, 5, 1), dtype=float64, numpy=\n",
       "array([[[[3.],\n",
       "         [3.],\n",
       "         [2.],\n",
       "         [1.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [3.],\n",
       "         [1.]],\n",
       "\n",
       "        [[3.],\n",
       "         [1.],\n",
       "         [2.],\n",
       "         [2.],\n",
       "         [3.]],\n",
       "\n",
       "        [[2.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [2.],\n",
       "         [2.]],\n",
       "\n",
       "        [[2.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.]]]])>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XXX = tf.constant([[3,3,2,1,0],[0,0,1,3,1],[3,1,2,2,3],[2,0,0,2,2],[2,0,0,0,1]],dtype=tf.float64).reshape(1,5,5,1)\n",
    "XXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "104a3d5e-4d14-424f-9d20-77804ae81e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2d = tf.keras.layers.Conv2D(1,(3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c27e88fd-742d-4e2e-8f17-ddf2eab26451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f786e249-2e89-481e-b1d1-784fdd380450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3, 3, 1), dtype=float32, numpy=\n",
       "array([[[[-0.75701153],\n",
       "         [-1.5324322 ],\n",
       "         [-2.275369  ]],\n",
       "\n",
       "        [[-0.07609195],\n",
       "         [-0.71050227],\n",
       "         [ 0.36970985]],\n",
       "\n",
       "        [[-0.39251935],\n",
       "         [ 0.39295316],\n",
       "         [-1.08425   ]]]], dtype=float32)>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d(XXX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "eabda30b-5d5c-4f57-baa1-8abfc1785c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 1, 1)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d.get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c2aa5d5b-bd9c-4ec5-9a72-02bc22c9f4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "_w = np.array([[0,1,2],[2,2,0],[0,1,2]],dtype=np.float32).reshape(3, 3, 1, 1)\n",
    "_b = np.array([0],dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "bdab938b-d408-4cb1-b59f-6d6ed8764be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2d.set_weights([_w,_b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "12a660da-5cec-4f3d-aa84-cf8999878550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=\n",
       "array([[[12., 12., 17.],\n",
       "        [10., 17., 19.],\n",
       "        [ 9.,  6., 14.]]], dtype=float32)>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d(XXX).reshape(1,3,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69c37de-9107-45d5-9c7c-67f2a8617233",
   "metadata": {
    "tags": []
   },
   "source": [
    "### test5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f00dc2-059b-42de-b41f-59b2f10cbdeb",
   "metadata": {},
   "source": [
    "`-` conv2의 채널이 여러개라면? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "464ca645-5b77-493b-9f78-016fde8c261e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2, 2), dtype=float64, numpy=\n",
       "array([[[1., 1.],\n",
       "        [1., 1.]]])>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XXX = tnp.array([1]*1*2*2*1,dtype=tf.float64).reshape(1,2,2,1)\n",
    "XXX.reshape(1,2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3cbb1b23-9ad7-4197-88c0-ca7503206754",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2d = tf.keras.layers.Conv2D(4,(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "629216fc-438a-4803-95be-f5a2bc77e419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1, 1, 4), dtype=float32, numpy=\n",
       "array([[[[-0.44725284, -0.2634663 ,  0.17193237,  1.0976446 ]]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d(XXX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "652a4f65-9173-4f57-a281-814211bb9ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 1, 1, 4])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d(XXX).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213e5e27-adf1-4599-9a17-895c69e4e2a0",
   "metadata": {},
   "source": [
    "- conv2d : (2,2,1) -> (1,1,4) 로 바꾸는 변환 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "67d7e9ec-8021-44cd-bd4f-52fd2cb028bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.4472528"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(conv2d.weights[0])[...,0].sum() ## conv2d(XXX)의 첫번째 채널 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "cf249c29-8b31-4264-ab4c-9d344cc1e08b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.2634663"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(conv2d.weights[0])[...,1].sum() ## conv2d(XXX)의 두번째 채널 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "647946be-8d79-4e6b-bd29-e5c3f6068f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17193237"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(conv2d.weights[0])[...,2].sum() ## conv2d(XXX)의 세번째 채널 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d0588143-bd7b-4ae2-9c4a-2e045f8045a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0976446"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(conv2d.weights[0])[...,3].sum() ## conv2d(XXX)의 네번째 채널 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a86516-be5d-47cd-aa2c-9bfc3d8e33c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### test6 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70ac936-cf6f-425d-ade4-bd903fb0af02",
   "metadata": {},
   "source": [
    "`-` X의 채널도 여러개이고, conv2의 채널도 여러개라면? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "0421fcb9-cc82-4f8c-b2a2-7dcf40b73d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "XXX = tnp.array([1]*1*2*2*3,dtype=tf.float64).reshape(1,2,2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "7d23577e-e3b0-4e35-b6b3-aa55743ec3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2d = tf.keras.layers.Conv2D(4,(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f90064b6-963c-463e-9aeb-87d30a18b5a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1, 1, 4), dtype=float32, numpy=\n",
       "array([[[[-0.21142393, -0.2087717 ,  1.7372127 ,  0.44387752]]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d(XXX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459021c4-ec5f-40a9-8291-8ea47f83abe1",
   "metadata": {},
   "source": [
    "- conv2d: (2,2,3) -> (1,1,4) 로 만들어 주는 변환 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "442e45a2-7c2f-4d1e-90a1-6685bb3e1d87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'conv2d_12/kernel:0' shape=(2, 2, 3, 4) dtype=float32, numpy=\n",
       " array([[[[ 0.05917424, -0.28489804,  0.11780715, -0.04244581],\n",
       "          [ 0.17721492, -0.22674735,  0.4233629 ,  0.38828826],\n",
       "          [-0.19064838, -0.32950848,  0.44972152, -0.27025908]],\n",
       " \n",
       "         [[-0.27793118,  0.04875344,  0.15190583, -0.10116643],\n",
       "          [ 0.00985605,  0.39692885, -0.36121044,  0.28199434],\n",
       "          [ 0.11366147,  0.07311636,  0.43144172, -0.14816672]]],\n",
       " \n",
       " \n",
       "        [[[ 0.21962047,  0.08759755,  0.05900085,  0.20004088],\n",
       "          [ 0.05466127, -0.11544552,  0.12602174,  0.0126003 ],\n",
       "          [-0.39480078, -0.2934072 ,  0.11134905,  0.01866451]],\n",
       " \n",
       "         [[ 0.38467884,  0.02177629, -0.21719636, -0.42347163],\n",
       "          [-0.38105386,  0.3438273 ,  0.03691953,  0.4573207 ],\n",
       "          [ 0.01414302,  0.06923515,  0.40808922,  0.0704782 ]]]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'conv2d_12/bias:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d.weights ## 처음 (2,2)는 window size // 3은 XXX의 채널수 // 4는 conv(XXX)의 채널수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "6ec015cb-4127-4153-bf5b-5b60f42b46ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[[[-0.21142393 -0.2087717   1.7372127   0.44387752]]]], shape=(1, 1, 1, 4), dtype=float32)\n",
      "-0.21142393\n",
      "-0.20877159\n",
      "1.7372127\n",
      "0.44387752\n"
     ]
    }
   ],
   "source": [
    "print(conv2d(XXX)) \n",
    "print(np.array(conv2d.weights[0])[...,0].sum())\n",
    "print(np.array(conv2d.weights[0])[...,1].sum())\n",
    "print(np.array(conv2d.weights[0])[...,2].sum())\n",
    "print(np.array(conv2d.weights[0])[...,3].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "7c6609a3-983a-4b3f-9668-6459a9f9eebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_red = np.array(conv2d.weights[0])[...,0][...,0]\n",
    "W_green = np.array(conv2d.weights[0])[...,0][...,1]\n",
    "W_blue = np.array(conv2d.weights[0])[...,0][...,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "99a69d74-11c0-48fe-8308-6396b9e94744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.21142393"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(W_red+W_green+W_blue).sum() ### convXXX의 첫채널 결과 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e925ea08-b822-49a0-8374-668560d20e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.20877162"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_red = np.array(conv2d.weights[0])[...,1][...,0]\n",
    "W_green = np.array(conv2d.weights[0])[...,1][...,1]\n",
    "W_blue = np.array(conv2d.weights[0])[...,1][...,2]\n",
    "(W_red+W_green+W_blue).sum() ### convXXX의 두번째 채널 결과 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95ce628-66ee-43b0-93a7-d2a9c3f9ba0b",
   "metadata": {},
   "source": [
    "## hw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd9beff-6c81-4cec-88b6-e8732ac68422",
   "metadata": {},
   "source": [
    "아래와 같은 흑백이미지가 있다고 하자. \n",
    "```\n",
    "0 0 0 1 1 1 \n",
    "0 0 0 1 1 1 \n",
    "0 0 0 1 1 1 \n",
    "0 0 0 1 1 1 \n",
    "0 0 0 1 1 1\n",
    "0 0 0 1 1 1 \n",
    "```\n",
    "\n",
    "위의 이미지에 아래와 같은 weight를 가진 필터를 적용하여 convolution한 결과를 계산하라. (bias는 0으로 가정한다) \n",
    "```\n",
    "-1 1 \n",
    "-1 1 \n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
